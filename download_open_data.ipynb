{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import urllib.request\n",
    "import re\n",
    "import os\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# *** CHANGE THIS as appropriate ***:\n",
    "# Base path to save all data to\n",
    "my_base_path = \"/home/sergey/Desktop/HackOnData/downloaded_data/\"\n",
    "\n",
    "# List of data formats that we don't want to download\n",
    "skip_download = []\n",
    "# skip_download = ['HTML','CSV','PDF','XLS','ZIP','XML','TXT','GML']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# INPUT: URL to json file\n",
    "# OUTPUT: json data\n",
    "def get_jsonparsed_data(json_url):\n",
    "    response = urllib.request.urlopen(json_url)\n",
    "    str_response = response.read().decode('utf-8')\n",
    "    return json.loads(str_response)\n",
    "\n",
    "\n",
    "# INPUT: Name of file with URLs. Finds URLs that point to open.canada.\n",
    "# OUTPUT: URLs to json files, the corresponding open.canada web pages, and open.canada IDs.\n",
    "def get_json_urls(hyperlinks_text_file_name):\n",
    "    f = open(hyperlinks_text_file_name, 'r')\n",
    "    json_urls = []; # list of URLs to json metadata files of open.canada data\n",
    "    open_canada_urls = []; # corresponding list of URLs to open.canada data\n",
    "    open_canada_IDs = []; # corresponding IDs\n",
    "    for line in f:\n",
    "#         print(line,end='')\n",
    "        match = re.search('open.canada.ca', line) # match = re.search(pat, text)\n",
    "        if match:\n",
    "#             print(line,end='')\n",
    "            ID = re.findall('/dataset/(.+)', line)\n",
    "#             print(ID)\n",
    "            json_urls.append(\"http://open.canada.ca/data/api/action/package_show?id=\" + str(ID[0]))\n",
    "            open_canada_urls.append(line.strip('\\n'))\n",
    "            open_canada_IDs.append(ID[0])\n",
    "    f.close()\n",
    "    return (json_urls, open_canada_urls, open_canada_IDs)\n",
    "\n",
    "\n",
    "# INPUT: json description provided by open.canada (and a URL to open.canada web-page)\n",
    "# OUTPUT: metadata in our format\n",
    "def parse_orig_json(json_data, open_canada_url):\n",
    "    my_metadata = {} # create empty dict to be filled with metadata\n",
    "    my_metadata['title'] = json_data['result'] ['title']\n",
    "    my_metadata['source_page'] = open_canada_url\n",
    "    \n",
    "    # fields below still need to be filled with actual values\n",
    "    my_metadata['source_files'] = [] # ['http://url_to_source_file_1','http://url_to_source_file_2']\n",
    "    my_metadata['Category'] = 'Public Administration'\n",
    "    my_metadata['data_last_modified'] ='' #'<2016-06-30>'\n",
    "    my_metadata['data_schema'] = {'field_1': 'type:<string/integer/decimal/date>'}\n",
    "    my_metadata['description'] = 'A description'\n",
    "    my_metadata['license'] = 'open'\n",
    "    my_metadata['tags'] = ['tag_1', 'tag_2', 'tag_3']\n",
    "    my_metadata['update_frequency'] = '<streaming/hourly/daily/monthly/no_updates>'\n",
    "    return my_metadata\n",
    "\n",
    "\n",
    "# Saves file from URL to folder_name, using specified file_name or automatically assigned one.\n",
    "# INPUT: URL; folder_name where file will be saved; file_name = 0 for automatic assignment.\n",
    "def download_file(URL, folder_name, file_name = 0): \n",
    "    if file_name == 0: # if file name is not specified\n",
    "        file_name = os.path.basename(URL) # get file name\n",
    "    full_path_to_save = os.path.join(folder_name, file_name)\n",
    "    try: urllib.request.urlretrieve(URL, full_path_to_save)\n",
    "    except urllib.request.HTTPError: # If unable to download, save failed URL to download_errors.txt\n",
    "        print('There was an error with the request')\n",
    "        f = open(os.path.join(folder_name, 'download_errors.txt'), 'a')\n",
    "        f.write(URL + '\\n')\n",
    "        f.close()\n",
    "\n",
    "\n",
    "def get_all_data_types(open_canada_IDs,json_urls):\n",
    "    # Find all types of data resouces, count number of files of each type and get the following result:\n",
    "    #         {'CSV': 466,\n",
    "    #          'HTML': 211,\n",
    "    #          'JSON': 3,\n",
    "    #          'PDF': 27,\n",
    "    #          'SHAPE': 3,\n",
    "    #          'TXT': 18,\n",
    "    #          'XLS': 111,\n",
    "    #          'XML': 92,\n",
    "    #          'ZIP': 38,\n",
    "    #          'doc': 3,\n",
    "    #          'fgdb / gdb': 1,\n",
    "    #          'gml': 3,\n",
    "    #          'jpeg 2000': 19,\n",
    "    #          'kml / kmz': 1,\n",
    "    #          'other': 54,\n",
    "    #          'rtf': 2,\n",
    "    #          'wfs': 1,\n",
    "    #          'wms': 1})\n",
    "    # Can list these types in skip_download = [] to skip downloading certain types.\n",
    "\n",
    "    res_type = [];\n",
    "    for idx in range(0,len(open_canada_IDs)):\n",
    "        print(\"Processing data source \" + str(idx) + \", ID: \" + str(open_canada_IDs[idx]))\n",
    "        json_data = get_jsonparsed_data( json_urls [ idx ] )\n",
    "        for res in json_data['result']['resources']:\n",
    "            res_type.append(res['format'])\n",
    "\n",
    "    set(res_type)\n",
    "    res_type.sort()\n",
    "    return Counter(res_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get json_urls, open_canada_urls and open_canada_IDs from the text file containing hyperlinks.\n",
    "( json_urls , open_canada_urls, open_canada_IDs ) = get_json_urls(\"hyperlinks.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Main loop for downloading data from open.data\n",
    "\n",
    "# for idx in range(0,1):\n",
    "for idx in range(0,len(open_canada_IDs)):\n",
    "    print(\"\\nProcessing data source \" + str(idx) + \", ID: \" + str(open_canada_IDs[idx]))\n",
    "    folder_path = os.path.join(my_base_path, open_canada_IDs[idx])\n",
    "    print(folder_path)\n",
    "    \n",
    "    # create folder to download files to\n",
    "    if not os.path.exists(folder_path):  os.makedirs(folder_path) \n",
    "    \n",
    "    # download original json\n",
    "    orig_json_filename = open_canada_IDs[idx] + '.json';\n",
    "    download_file(json_urls[idx], folder_path, orig_json_filename)\n",
    "    \n",
    "    # get data from original json\n",
    "    json_data = get_jsonparsed_data( json_urls [ idx ] )\n",
    "    \n",
    "    # create metadata from original json\n",
    "    metadata = parse_orig_json( json_data, open_canada_urls[ idx ] )\n",
    "    \n",
    "    # download all data resources\n",
    "    for res in json_data['result']['resources']:\n",
    "        if res['format'] in skip_download:\n",
    "            print(\"  Skipping: \" + res['url'])\n",
    "        else:\n",
    "            print(\"  Downloading: \" + res['url'])\n",
    "            download_file(res['url'], folder_path)\n",
    "            metadata['source_files'].append(res['url'])\n",
    "    \n",
    "    # save metadata\n",
    "    fp = open(os.path.join ( folder_path, 'metadata.json' ) , 'w');\n",
    "    json.dump(metadata,fp)\n",
    "    fp.close();"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
